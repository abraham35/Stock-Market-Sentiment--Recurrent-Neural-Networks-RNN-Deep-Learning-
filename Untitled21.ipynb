{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP8NF838NYhzgBL807tAukF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abraham35/Stock-Market-Sentiment--Recurrent-Neural-Networks-RNN-Deep-Learning-/blob/main/Untitled21.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "rDfBNtwyKHFI"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "from keras.optimizers import Adam\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n"
      ],
      "metadata": {
        "id": "P0OMEXojKIYX"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "DS4TWWIjKe4O",
        "outputId": "d88015f2-e6b5-4c24-f1fa-5abf81dde556"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-83c3d81a-e9c2-457e-993f-e1f1169a8bf3\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-83c3d81a-e9c2-457e-993f-e1f1169a8bf3\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving stock_data.csv to stock_data.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('stock_data.csv')"
      ],
      "metadata": {
        "id": "vhFWigyrK1J1"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display first 5 rows\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5wF1xLVYLDLd",
        "outputId": "15e4ae36-d6f5-44b9-8b46-408b4f0f0db9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                Text  Sentiment\n",
            "0  Kickers on my watchlist XIDE TIT SOQ PNK CPW B...          1\n",
            "1  user: AAP MOVIE. 55% return for the FEA/GEED i...          1\n",
            "2  user I'd be afraid to short AMZN - they are lo...          1\n",
            "3                                  MNTA Over 12.00            1\n",
            "4                                   OI  Over 21.37            1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Step 2: Data Preprocessing\n",
        "# Text preprocessing and encoding sentiment labels\n",
        "texts = df['Text']  # Assuming 'text' column contains news articles\n",
        "labels = df['Sentiment']  # Assuming 'sentiment' column contains sentiment labels (-1 for negative, 1 for positive)\n"
      ],
      "metadata": {
        "id": "wINEQEYrLGOj"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure labels are in binary format (1 for positive, 0 for negative)\n",
        "labels = labels.apply(lambda x: 1 if x == 1 else 0)  # Convert -1 to 0 for binary classification"
      ],
      "metadata": {
        "id": "l5YifvA_Loyq"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Tokenization & Padding\n",
        "# Tokenizing the text\n",
        "tokenizer = Tokenizer(num_words=10000)  # Limit the vocabulary size to 10,000 most frequent words\n",
        "tokenizer.fit_on_texts(texts)\n",
        "\n",
        "# Convert texts to sequences of integers\n",
        "X = tokenizer.texts_to_sequences(texts)\n",
        "\n",
        "# Padding sequences to ensure they have the same length\n",
        "X = pad_sequences(X, padding='post', maxlen=100)  # Max length of 100 words per input\n"
      ],
      "metadata": {
        "id": "i2DUjr54Lvh6"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Train-Test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "qGPLLfNQL6m_"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Build the RNN Model using LSTM\n",
        "model = Sequential()\n",
        "\n",
        "# Embedding layer (convert input sequence to word embeddings)\n",
        "model.add(Embedding(input_dim=10000, output_dim=100, input_length=100))\n",
        "\n",
        "# LSTM Layer (Recurrent Neural Network)\n",
        "model.add(LSTM(128, return_sequences=False))\n",
        "\n",
        "# Dropout layer (to avoid overfitting)\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "# Fully connected output layer (1 output neuron for binary classification)\n",
        "model.add(Dense(1, activation='sigmoid'))  # Sigmoid for binary classification (0 or 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VIgW3afPMDa-",
        "outputId": "5f51a97e-5634-4458-9068-90983868cb4d"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6: Compile the Model\n",
        "model.compile(loss='binary_crossentropy',  # Binary cross-entropy loss for binary classification\n",
        "              optimizer=Adam(),\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "o-qyHQP_MOZZ"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 7: Train the Model\n",
        "history = model.fit(X_train, y_train, epochs=50, batch_size=64, validation_data=(X_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "x1e6gNtJMXRM",
        "outputId": "235d8b74-2355-4fa7-d619-3a1bec2fe6e0"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 269ms/step - accuracy: 0.6415 - loss: 0.6564 - val_accuracy: 0.6316 - val_loss: 0.6583\n",
            "Epoch 2/50\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 256ms/step - accuracy: 0.6345 - loss: 0.6586 - val_accuracy: 0.6316 - val_loss: 0.6587\n",
            "Epoch 3/50\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 269ms/step - accuracy: 0.6415 - loss: 0.6554 - val_accuracy: 0.6316 - val_loss: 0.6582\n",
            "Epoch 4/50\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 248ms/step - accuracy: 0.6305 - loss: 0.6593 - val_accuracy: 0.6316 - val_loss: 0.6591\n",
            "Epoch 5/50\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 249ms/step - accuracy: 0.6392 - loss: 0.6572 - val_accuracy: 0.6316 - val_loss: 0.6584\n",
            "Epoch 6/50\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 275ms/step - accuracy: 0.6374 - loss: 0.6582 - val_accuracy: 0.6316 - val_loss: 0.6582\n",
            "Epoch 7/50\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 250ms/step - accuracy: 0.6443 - loss: 0.6530 - val_accuracy: 0.6316 - val_loss: 0.6587\n",
            "Epoch 8/50\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 251ms/step - accuracy: 0.6395 - loss: 0.6550 - val_accuracy: 0.6316 - val_loss: 0.6586\n",
            "Epoch 9/50\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 255ms/step - accuracy: 0.6346 - loss: 0.6573 - val_accuracy: 0.6316 - val_loss: 0.6588\n",
            "Epoch 10/50\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 247ms/step - accuracy: 0.6291 - loss: 0.6621 - val_accuracy: 0.6316 - val_loss: 0.6581\n",
            "Epoch 11/50\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 271ms/step - accuracy: 0.6431 - loss: 0.6539 - val_accuracy: 0.6316 - val_loss: 0.6581\n",
            "Epoch 12/50\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 247ms/step - accuracy: 0.6325 - loss: 0.6577 - val_accuracy: 0.6316 - val_loss: 0.6582\n",
            "Epoch 13/50\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 249ms/step - accuracy: 0.6397 - loss: 0.6554 - val_accuracy: 0.6316 - val_loss: 0.6583\n",
            "Epoch 14/50\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 267ms/step - accuracy: 0.6264 - loss: 0.6614 - val_accuracy: 0.6316 - val_loss: 0.6592\n",
            "Epoch 15/50\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 246ms/step - accuracy: 0.6292 - loss: 0.6601 - val_accuracy: 0.6316 - val_loss: 0.6583\n",
            "Epoch 16/50\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 273ms/step - accuracy: 0.6395 - loss: 0.6550 - val_accuracy: 0.6316 - val_loss: 0.6584\n",
            "Epoch 17/50\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 247ms/step - accuracy: 0.6333 - loss: 0.6580 - val_accuracy: 0.6316 - val_loss: 0.6583\n",
            "Epoch 18/50\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 248ms/step - accuracy: 0.6448 - loss: 0.6519 - val_accuracy: 0.6316 - val_loss: 0.6581\n",
            "Epoch 19/50\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 271ms/step - accuracy: 0.6364 - loss: 0.6548 - val_accuracy: 0.6316 - val_loss: 0.6581\n",
            "Epoch 20/50\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 249ms/step - accuracy: 0.6389 - loss: 0.6551 - val_accuracy: 0.6316 - val_loss: 0.6586\n",
            "Epoch 21/50\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 280ms/step - accuracy: 0.6253 - loss: 0.6609 - val_accuracy: 0.6316 - val_loss: 0.6626\n",
            "Epoch 22/50\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 252ms/step - accuracy: 0.6427 - loss: 0.6529 - val_accuracy: 0.6316 - val_loss: 0.6582\n",
            "Epoch 23/50\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 250ms/step - accuracy: 0.6317 - loss: 0.6587 - val_accuracy: 0.6316 - val_loss: 0.6584\n",
            "Epoch 24/50\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 269ms/step - accuracy: 0.6359 - loss: 0.6564 - val_accuracy: 0.6316 - val_loss: 0.6581\n",
            "Epoch 25/50\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 248ms/step - accuracy: 0.6277 - loss: 0.6612 - val_accuracy: 0.6316 - val_loss: 0.6582\n",
            "Epoch 26/50\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 272ms/step - accuracy: 0.6423 - loss: 0.6534 - val_accuracy: 0.6316 - val_loss: 0.6581\n",
            "Epoch 27/50\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 248ms/step - accuracy: 0.6340 - loss: 0.6593 - val_accuracy: 0.6316 - val_loss: 0.6582\n",
            "Epoch 28/50\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 247ms/step - accuracy: 0.6375 - loss: 0.6562 - val_accuracy: 0.6316 - val_loss: 0.6586\n",
            "Epoch 29/50\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 245ms/step - accuracy: 0.6315 - loss: 0.6602 - val_accuracy: 0.6316 - val_loss: 0.6586\n",
            "Epoch 30/50\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 271ms/step - accuracy: 0.6419 - loss: 0.6540 - val_accuracy: 0.6316 - val_loss: 0.6582\n",
            "Epoch 31/50\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 255ms/step - accuracy: 0.6265 - loss: 0.6607 - val_accuracy: 0.6316 - val_loss: 0.6590\n",
            "Epoch 32/50\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 249ms/step - accuracy: 0.6296 - loss: 0.6593 - val_accuracy: 0.6316 - val_loss: 0.6584\n",
            "Epoch 33/50\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 261ms/step - accuracy: 0.6419 - loss: 0.6544 - val_accuracy: 0.6316 - val_loss: 0.6582\n",
            "Epoch 34/50\n",
            "\u001b[1m30/73\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 203ms/step - accuracy: 0.6410 - loss: 0.6537"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-21605dd91d5f>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Step 7: Train the Model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    318\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menumerate_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pythonify_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    876\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m       results = tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    879\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1320\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1321\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1550\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1552\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1553\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1554\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 8: Evaluate the Model\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Model Accuracy: {accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4YJ4edeNrcb",
        "outputId": "ae7fa360-61d7-4f5b-910b-32d607d8c889"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - accuracy: 0.6305 - loss: 0.6594\n",
            "Model Accuracy: 63.16%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 9: Plot Training History\n",
        "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Test Accuracy')\n",
        "plt.title('Model Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(loc='best')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "ramzUqCXMbTR",
        "outputId": "0150ddc0-277e-4351-cfa6-b6460ea4db2f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "# Input layer (First dense layer, assuming input features are 128-dimensional)\n",
        "model.add(Dense(256, activation='relu', input_dim=128))\n",
        "model.add(Dropout(0.5))  # Dropout layer with 50% drop rate\n",
        "model.add(BatchNormalization())  # Batch normalization to stabilize training\n",
        "\n",
        "# Second dense layer with more neurons\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# Third dense layer with even more neurons\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# Output layer (with sigmoid activation for binary classification or softmax for multi-class)\n",
        "model.add(Dense(1, activation='sigmoid'))  # Use 'softmax' for multi-class classification\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dl7MIAykRBt9",
        "outputId": "c0f0b3c4-7b84-46dc-bc03-69211792d127"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ... (Previous code for LSTM model) ...\n",
        "\n",
        "# Define the Dense layer model\n",
        "model_dense = Sequential()  # Create a new model with a different name\n",
        "model_dense.add(Dense(256, activation='relu', input_dim=100))  # Change input_dim to 100\n",
        "model_dense.add(Dropout(0.5))\n",
        "model_dense.add(BatchNormalization())\n",
        "model_dense.add(Dense(512, activation='relu'))\n",
        "model_dense.add(Dropout(0.5))\n",
        "model_dense.add(BatchNormalization())\n",
        "model_dense.add(Dense(256, activation='relu'))\n",
        "model_dense.add(Dropout(0.5))\n",
        "model_dense.add(BatchNormalization())\n",
        "model_dense.add(Dense(1, activation='sigmoid'))\n",
        "model_dense.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# ... (Data splitting and training code using model_dense) ...\n",
        "\n",
        "# Train the model with callbacks\n",
        "history = model_dense.fit(X_train, y_train, epochs=50, validation_data=(X_val, y_val),\n",
        "                         callbacks=[lr_scheduler, early_stopping])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1BeuJ5Y8YH8y",
        "outputId": "3e7bd88d-8c69-4286-fc56-a965206bdb2c"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.5473 - loss: 0.8226 - val_accuracy: 0.6168 - val_loss: 0.6586 - learning_rate: 0.0010\n",
            "Epoch 2/50\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.5978 - loss: 0.7387 - val_accuracy: 0.6329 - val_loss: 0.6437 - learning_rate: 0.0010\n",
            "Epoch 3/50\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.6022 - loss: 0.6985 - val_accuracy: 0.6421 - val_loss: 0.6385 - learning_rate: 0.0010\n",
            "Epoch 4/50\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.6009 - loss: 0.6931 - val_accuracy: 0.6398 - val_loss: 0.6376 - learning_rate: 0.0010\n",
            "Epoch 5/50\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6157 - loss: 0.6667 - val_accuracy: 0.6387 - val_loss: 0.6382 - learning_rate: 0.0010\n",
            "Epoch 6/50\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.6294 - loss: 0.6601 - val_accuracy: 0.6352 - val_loss: 0.6390 - learning_rate: 0.0010\n",
            "Epoch 7/50\n",
            "\u001b[1m125/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6203 - loss: 0.6530\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.6203 - loss: 0.6531 - val_accuracy: 0.6341 - val_loss: 0.6408 - learning_rate: 0.0010\n",
            "Epoch 8/50\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.6238 - loss: 0.6516 - val_accuracy: 0.6433 - val_loss: 0.6376 - learning_rate: 5.0000e-04\n",
            "Epoch 9/50\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6167 - loss: 0.6486 - val_accuracy: 0.6387 - val_loss: 0.6364 - learning_rate: 5.0000e-04\n",
            "Epoch 10/50\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6339 - loss: 0.6437 - val_accuracy: 0.6421 - val_loss: 0.6385 - learning_rate: 5.0000e-04\n",
            "Epoch 11/50\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6311 - loss: 0.6407 - val_accuracy: 0.6421 - val_loss: 0.6360 - learning_rate: 5.0000e-04\n",
            "Epoch 12/50\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6335 - loss: 0.6442 - val_accuracy: 0.6456 - val_loss: 0.6377 - learning_rate: 5.0000e-04\n",
            "Epoch 13/50\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6273 - loss: 0.6412 - val_accuracy: 0.6387 - val_loss: 0.6337 - learning_rate: 5.0000e-04\n",
            "Epoch 14/50\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6313 - loss: 0.6367 - val_accuracy: 0.6398 - val_loss: 0.6347 - learning_rate: 5.0000e-04\n",
            "Epoch 15/50\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6288 - loss: 0.6487 - val_accuracy: 0.6479 - val_loss: 0.6355 - learning_rate: 5.0000e-04\n",
            "Epoch 16/50\n",
            "\u001b[1m125/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6464 - loss: 0.6296\n",
            "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - accuracy: 0.6462 - loss: 0.6297 - val_accuracy: 0.6433 - val_loss: 0.6375 - learning_rate: 5.0000e-04\n",
            "Epoch 17/50\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.6438 - loss: 0.6307 - val_accuracy: 0.6444 - val_loss: 0.6364 - learning_rate: 2.5000e-04\n",
            "Epoch 18/50\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.6362 - loss: 0.6412 - val_accuracy: 0.6467 - val_loss: 0.6372 - learning_rate: 2.5000e-04\n",
            "Epoch 18: early stopping\n",
            "Restoring model weights from the end of the best epoch: 13.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 8: Evaluate the Model\n",
        "# The model variable is pointing to the Dense model (model) instead of the LSTM model.\n",
        "# Changed 'model' to 'model_dense' assuming you want to evaluate the LSTM model.\n",
        "loss, accuracy = model_dense.evaluate(X_test, y_test)\n",
        "print(f\"Model Accuracy: {accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ugxtqEZ5ZF3n",
        "outputId": "51195ff6-2f1e-42f3-c6eb-ee63685f6f49"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6050 - loss: 0.6521\n",
            "Model Accuracy: 64.21%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 10: Prediction on Incoming Data (New Data)"
      ],
      "metadata": {
        "id": "b9cb7kWcZQU2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example incoming data\n",
        "incoming_data = [\"Stock prices rise as tech stocks surge\",\n",
        "                 \"Market crashes due to geopolitical tensions\",\n",
        "                 \"Financial experts predict a stable growth period\"]\n",
        "\n",
        "# Preprocess incoming data (same steps as the training data)\n",
        "incoming_data_seq = tokenizer.texts_to_sequences(incoming_data)\n",
        "incoming_data_seq = pad_sequences(incoming_data_seq, padding='post', maxlen=100)\n",
        "\n",
        "# Predict sentiment for incoming data\n",
        "# Use the LSTM model (model_dense) instead of the Dense layer model (model)\n",
        "predictions = model_dense.predict(incoming_data_seq)  # Changed 'model' to 'model_dense'\n",
        "\n",
        "# Convert predictions to sentiment labels (1: Positive, 0: Negative)\n",
        "predicted_sentiments = [\"Positive\" if pred > 0.5 else \"Negative\" for pred in predictions]\n",
        "\n",
        "# Print results\n",
        "for text, sentiment in zip(incoming_data, predicted_sentiments):\n",
        "    print(f\"Text: {text}\\nPredicted Sentiment: {sentiment}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b24iKY_HamrL",
        "outputId": "eb663a59-9f09-4fb5-e036-1208002ba412"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step\n",
            "Text: Stock prices rise as tech stocks surge\n",
            "Predicted Sentiment: Positive\n",
            "\n",
            "Text: Market crashes due to geopolitical tensions\n",
            "Predicted Sentiment: Positive\n",
            "\n",
            "Text: Financial experts predict a stable growth period\n",
            "Predicted Sentiment: Positive\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SsXubNQkay3X"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}